{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n\n**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n\nThis notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Best practices for the real world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Getting the most out of your models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Using KerasTuner"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-11T06:41:22.521805Z",
     "start_time": "2024-06-11T06:41:20.505709Z"
    }
   },
   "source": [
    "!pip install keras-tuner -q"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A KerasTuner model-building function**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-11T07:01:43.780852Z",
     "start_time": "2024-06-11T07:01:40.462818Z"
    }
   },
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(hp):\n",
    "    units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(units, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A KerasTuner `HyperModel`**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-11T07:01:44.458823Z",
     "start_time": "2024-06-11T07:01:43.782586Z"
    }
   },
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "class SimpleMLP(kt.HyperModel):\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
    "        model = keras.Sequential([\n",
    "            layers.Dense(units, activation=\"relu\"),\n",
    "            layers.Dense(self.num_classes, activation=\"softmax\")\n",
    "        ])\n",
    "        optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"])\n",
    "        return model\n",
    "\n",
    "hypermodel = SimpleMLP(num_classes=10)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-11T07:01:44.553879Z",
     "start_time": "2024-06-11T07:01:44.459532Z"
    }
   },
   "source": [
    "tuner = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory=\"mnist_kt_test\",\n",
    "    overwrite=True,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 16:01:44.473672: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-06-11 16:01:44.473856: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-11T07:01:44.557667Z",
     "start_time": "2024-06-11T07:01:44.555396Z"
    }
   },
   "source": [
    "tuner.search_space_summary()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 16, 'sampling': 'linear'}\n",
      "optimizer (Choice)\n",
      "{'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam'], 'ordered': False}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape((-1, 28 * 28)).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape((-1, 28 * 28)).astype(\"float32\") / 255\n",
    "x_train_full = x_train[:]\n",
    "y_train_full = y_train[:]\n",
    "num_val_samples = 10000\n",
    "x_train, x_val = x_train[:-num_val_samples], x_train[-num_val_samples:]\n",
    "y_train, y_val = y_train[:-num_val_samples], y_train[-num_val_samples:]\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "]\n",
    "tuner.search(\n",
    "    x_train, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=2,\n",
    ")"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 07s]\n",
      "val_accuracy: 0.9722000062465668\n",
      "\n",
      "Best val_accuracy So Far: 0.9727999866008759\n",
      "Total elapsed time: 00h 13m 38s\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Querying the best hyperparameter configurations**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-11T07:15:22.832542Z",
     "start_time": "2024-06-11T07:15:22.830258Z"
    }
   },
   "source": [
    "top_n = 4\n",
    "best_hps = tuner.get_best_hyperparameters(top_n)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-11T07:15:22.835520Z",
     "start_time": "2024-06-11T07:15:22.833257Z"
    }
   },
   "source": [
    "def get_best_epoch(hp):\n",
    "    model = build_model(hp)\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", mode=\"min\", patience=10)\n",
    "    ]\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=100,\n",
    "        batch_size=128,\n",
    "        callbacks=callbacks)\n",
    "    val_loss_per_epoch = history.history[\"val_loss\"]\n",
    "    best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    return best_epoch"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-11T07:16:40.606607Z",
     "start_time": "2024-06-11T07:15:22.836155Z"
    }
   },
   "source": [
    "def get_best_trained_model(hp):\n",
    "    best_epoch = get_best_epoch(hp)\n",
    "    model.fit(\n",
    "        x_train_full, y_train_full,\n",
    "        batch_size=128, epochs=int(best_epoch * 1.2))\n",
    "    return model\n",
    "\n",
    "best_models = []\n",
    "for hp in best_hps:\n",
    "    model = get_best_trained_model(hp)\n",
    "    model.evaluate(x_test, y_test)\n",
    "    best_models.append(model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 16:15:23.215979: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/391 [============================>.] - ETA: 0s - loss: 0.4161 - accuracy: 0.8908"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 16:15:26.364124: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 4s 9ms/step - loss: 0.4156 - accuracy: 0.8909 - val_loss: 0.2288 - val_accuracy: 0.9361\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2103 - accuracy: 0.9398 - val_loss: 0.1710 - val_accuracy: 0.9522\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1605 - accuracy: 0.9537 - val_loss: 0.1422 - val_accuracy: 0.9599\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1317 - accuracy: 0.9622 - val_loss: 0.1263 - val_accuracy: 0.9649\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.1128 - accuracy: 0.9679 - val_loss: 0.1172 - val_accuracy: 0.9657\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0988 - accuracy: 0.9716 - val_loss: 0.1178 - val_accuracy: 0.9665\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.0879 - accuracy: 0.9743 - val_loss: 0.1089 - val_accuracy: 0.9690\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0784 - accuracy: 0.9775 - val_loss: 0.0994 - val_accuracy: 0.9698\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0709 - accuracy: 0.9797 - val_loss: 0.0980 - val_accuracy: 0.9704\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0642 - accuracy: 0.9812 - val_loss: 0.0930 - val_accuracy: 0.9723\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0583 - accuracy: 0.9832 - val_loss: 0.0947 - val_accuracy: 0.9726\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0535 - accuracy: 0.9844 - val_loss: 0.0961 - val_accuracy: 0.9718\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0493 - accuracy: 0.9858 - val_loss: 0.0936 - val_accuracy: 0.9723\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0457 - accuracy: 0.9872 - val_loss: 0.0950 - val_accuracy: 0.9723\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0416 - accuracy: 0.9886 - val_loss: 0.1029 - val_accuracy: 0.9714\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0380 - accuracy: 0.9894 - val_loss: 0.0929 - val_accuracy: 0.9746\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0351 - accuracy: 0.9901 - val_loss: 0.0930 - val_accuracy: 0.9748\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0325 - accuracy: 0.9911 - val_loss: 0.0941 - val_accuracy: 0.9752\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0298 - accuracy: 0.9918 - val_loss: 0.0933 - val_accuracy: 0.9748\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0285 - accuracy: 0.9923 - val_loss: 0.0961 - val_accuracy: 0.9756\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0257 - accuracy: 0.9933 - val_loss: 0.0946 - val_accuracy: 0.9747\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0237 - accuracy: 0.9938 - val_loss: 0.1024 - val_accuracy: 0.9732\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0216 - accuracy: 0.9941 - val_loss: 0.1011 - val_accuracy: 0.9749\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0203 - accuracy: 0.9944 - val_loss: 0.0998 - val_accuracy: 0.9740\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0186 - accuracy: 0.9952 - val_loss: 0.1043 - val_accuracy: 0.9747\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0169 - accuracy: 0.9960 - val_loss: 0.1044 - val_accuracy: 0.9738\n",
      "Best epoch: 16\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m best_models \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hp \u001B[38;5;129;01min\u001B[39;00m best_hps:\n\u001B[0;32m---> 10\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mget_best_trained_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     model\u001B[38;5;241m.\u001B[39mevaluate(x_test, y_test)\n\u001B[1;32m     12\u001B[0m     best_models\u001B[38;5;241m.\u001B[39mappend(model)\n",
      "Cell \u001B[0;32mIn[8], line 3\u001B[0m, in \u001B[0;36mget_best_trained_model\u001B[0;34m(hp)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_best_trained_model\u001B[39m(hp):\n\u001B[1;32m      2\u001B[0m     best_epoch \u001B[38;5;241m=\u001B[39m get_best_epoch(hp)\n\u001B[0;32m----> 3\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mfit(\n\u001B[1;32m      4\u001B[0m         x_train_full, y_train_full,\n\u001B[1;32m      5\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mint\u001B[39m(best_epoch \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1.2\u001B[39m))\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-11T07:16:40.608537Z",
     "start_time": "2024-06-11T07:16:40.608464Z"
    }
   },
   "source": [
    "best_models = tuner.get_best_models(top_n)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The art of crafting the right search space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The future of hyperparameter tuning: automated machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Model ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Scaling-up model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Speeding up training on GPU with mixed precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Understanding floating-point precision"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-11T07:16:40.609026Z",
     "start_time": "2024-06-11T07:16:40.608968Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "np_array = np.zeros((2, 2))\n",
    "tf_tensor = tf.convert_to_tensor(np_array)\n",
    "tf_tensor.dtype"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "np_array = np.zeros((2, 2))\n",
    "tf_tensor = tf.convert_to_tensor(np_array, dtype=\"float32\")\n",
    "tf_tensor.dtype"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Mixed-precision training in practice"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "from tensorflow import keras\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Multi-GPU training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Getting your hands on two or more GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Single-host, multi-device synchronous training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### TPU training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Using a TPU via Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Leveraging step fusing to improve TPU utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter13_best-practices-for-the-real-world.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
