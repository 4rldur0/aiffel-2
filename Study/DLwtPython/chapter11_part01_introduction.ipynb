{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n\n**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n\nThis notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Deep learning for text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Natural-language processing: The bird's eye view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Preparing text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Text standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Text splitting (tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Vocabulary indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using the TextVectorization layer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:50:18.703573Z",
     "start_time": "2024-06-10T02:50:18.695744Z"
    }
   },
   "source": [
    "import string\n",
    "\n",
    "class Vectorizer:\n",
    "    def standardize(self, text):\n",
    "        text = text.lower()\n",
    "        return \"\".join(char for char in text if char not in string.punctuation)\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        text = self.standardize(text)\n",
    "        return text.split()\n",
    "\n",
    "    def make_vocabulary(self, dataset):\n",
    "        self.vocabulary = {\"\": 0, \"[UNK]\": 1}\n",
    "        for text in dataset:\n",
    "            text = self.standardize(text)\n",
    "            tokens = self.tokenize(text)\n",
    "            for token in tokens:\n",
    "                if token not in self.vocabulary:\n",
    "                    self.vocabulary[token] = len(self.vocabulary)\n",
    "        self.inverse_vocabulary = dict(\n",
    "            (v, k) for k, v in self.vocabulary.items())\n",
    "\n",
    "    def encode(self, text):\n",
    "        text = self.standardize(text)\n",
    "        tokens = self.tokenize(text)\n",
    "        return [self.vocabulary.get(token, 1) for token in tokens]\n",
    "\n",
    "    def decode(self, int_sequence):\n",
    "        return \" \".join(\n",
    "            self.inverse_vocabulary.get(i, \"[UNK]\") for i in int_sequence)\n",
    "\n",
    "vectorizer = Vectorizer()\n",
    "dataset = [\n",
    "    \"I write, erase, rewrite\",\n",
    "    \"Erase again, and then\",\n",
    "    \"A poppy blooms.\",\n",
    "]\n",
    "vectorizer.make_vocabulary(dataset)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:50:19.781644Z",
     "start_time": "2024-06-10T02:50:19.773046Z"
    }
   },
   "source": [
    "test_sentence = \"I write, rewrite, and still rewrite again\"\n",
    "encoded_sentence = vectorizer.encode(test_sentence)\n",
    "print(encoded_sentence)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 5, 7, 1, 5, 6]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:50:20.323264Z",
     "start_time": "2024-06-10T02:50:20.320141Z"
    }
   },
   "source": [
    "decoded_sentence = vectorizer.decode(encoded_sentence)\n",
    "print(decoded_sentence)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i write rewrite and [UNK] rewrite again\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:50:20.811780Z",
     "start_time": "2024-06-10T02:50:20.798314Z"
    }
   },
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "text_vectorization = TextVectorization(\n",
    "    output_mode=\"int\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:50:21.228632Z",
     "start_time": "2024-06-10T02:50:21.221262Z"
    }
   },
   "source": [
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "def custom_standardization_fn(string_tensor):\n",
    "    lowercase_string = tf.strings.lower(string_tensor)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase_string, f\"[{re.escape(string.punctuation)}]\", \"\")\n",
    "\n",
    "def custom_split_fn(string_tensor):\n",
    "    return tf.strings.split(string_tensor)\n",
    "\n",
    "text_vectorization = TextVectorization(\n",
    "    output_mode=\"int\",\n",
    "    standardize=custom_standardization_fn,\n",
    "    split=custom_split_fn,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:50:21.985968Z",
     "start_time": "2024-06-10T02:50:21.789Z"
    }
   },
   "source": [
    "dataset = [\n",
    "    \"I write, erase, rewrite\",\n",
    "    \"Erase again, and then\",\n",
    "    \"A poppy blooms.\",\n",
    "]\n",
    "text_vectorization.adapt(dataset)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 11:50:21.892230: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Displaying the vocabulary**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:50:22.636243Z",
     "start_time": "2024-06-10T02:50:22.629254Z"
    }
   },
   "source": [
    "text_vectorization.get_vocabulary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'erase',\n",
       " 'write',\n",
       " 'then',\n",
       " 'rewrite',\n",
       " 'poppy',\n",
       " 'i',\n",
       " 'blooms',\n",
       " 'and',\n",
       " 'again',\n",
       " 'a']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:50:23.465449Z",
     "start_time": "2024-06-10T02:50:23.355836Z"
    }
   },
   "source": [
    "vocabulary = text_vectorization.get_vocabulary()\n",
    "test_sentence = \"I write, rewrite, and still rewrite again\"\n",
    "encoded_sentence = text_vectorization(test_sentence)\n",
    "print(encoded_sentence)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 7  3  5  9  1  5 10], shape=(7,), dtype=int64)\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:50:24.352662Z",
     "start_time": "2024-06-10T02:50:24.347998Z"
    }
   },
   "source": [
    "inverse_vocab = dict(enumerate(vocabulary))\n",
    "decoded_sentence = \" \".join(inverse_vocab[int(i)] for i in encoded_sentence)\n",
    "print(decoded_sentence)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i write rewrite and [UNK] rewrite again\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Two approaches for representing groups of words: Sets and sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Preparing the IMDB movie reviews data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:46:41.271411Z",
     "start_time": "2024-06-10T02:45:25.809433Z"
    }
   },
   "source": [
    "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf aclImdb_v1.tar.gz"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100 80.2M  100 80.2M    0     0  1276k      0  0:01:04  0:01:04 --:--:-- 3472k 0  0 --:--:--  0:00:10 --:--:--     0    0      0      0 --:--:--  0:00:17 --:--:--     0\r\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:48:11.272098Z",
     "start_time": "2024-06-10T02:48:04.645140Z"
    }
   },
   "source": [
    "!rm -r aclImdb/train/unsup"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:48:14.254604Z",
     "start_time": "2024-06-10T02:48:14.128236Z"
    }
   },
   "source": [
    "!cat aclImdb/train/pos/4077_10.txt"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:49:45.472262Z",
     "start_time": "2024-06-10T02:49:45.160862Z"
    }
   },
   "source": [
    "import os, pathlib, shutil, random\n",
    "\n",
    "base_dir = pathlib.Path(\"aclImdb\")\n",
    "val_dir = base_dir / \"val\"\n",
    "train_dir = base_dir / \"train\"\n",
    "for category in (\"neg\", \"pos\"):\n",
    "    try:\n",
    "        os.makedirs(val_dir / category)\n",
    "        files = os.listdir(train_dir / category)\n",
    "        random.Random(1337).shuffle(files)\n",
    "        num_val_samples = int(0.2 * len(files))\n",
    "        val_files = files[-num_val_samples:]\n",
    "        for fname in val_files:\n",
    "            shutil.move(train_dir / category / fname,\n",
    "                        val_dir / category / fname)\n",
    "    except:\n",
    "        pass"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:49:52.794070Z",
     "start_time": "2024-06-10T02:49:46.909350Z"
    }
   },
   "source": [
    "from tensorflow import keras\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\", batch_size=batch_size\n",
    ")\n",
    "val_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/val\", batch_size=batch_size\n",
    ")\n",
    "test_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/test\", batch_size=batch_size\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22500 files belonging to 2 classes.\n",
      "Metal device set to: Apple M2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 11:49:51.589790: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-06-10 11:49:51.590326: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2500 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Displaying the shapes and dtypes of the first batch**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:49:52.854615Z",
     "start_time": "2024-06-10T02:49:52.795272Z"
    }
   },
   "source": [
    "for inputs, targets in train_ds:\n",
    "    print(\"inputs.shape:\", inputs.shape)\n",
    "    print(\"inputs.dtype:\", inputs.dtype)\n",
    "    print(\"targets.shape:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets[0])\n",
    "    break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32,)\n",
      "inputs.dtype: <dtype: 'string'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor(b\"I kinda liked the film despite it's frenzied pace. BUT, I did not appreciate the comment that Canada was referred to as Montana North. It is definitely NOT Montana North and never will be. Americans wonder why they are perceived as arrogant in the rest of the world, and that is one reason why. Stop teaching the kids of the United States of America to think they own the planet. Such a centrist world view is not becoming of one of the world's great nations. Even in jest. I would never refer to the USA as 'Alberta South'. Walt would never put us down, so why start now. Other than that the film was pretty goofy, better luck next time.\", shape=(), dtype=string)\n",
      "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 11:49:52.813622: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Processing words as a set: The bag-of-words approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Single words (unigrams) with binary encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Preprocessing our datasets with a `TextVectorization` layer**"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:50:37.190934Z",
     "start_time": "2024-06-10T02:50:34.886399Z"
    }
   },
   "source": [
    "text_vectorization = TextVectorization(\n",
    "    max_tokens=20000,\n",
    "    output_mode=\"multi_hot\",\n",
    ")\n",
    "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "binary_1gram_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "binary_1gram_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "binary_1gram_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 11:50:34.938288: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Inspecting the output of our binary unigram dataset**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:50:41.550898Z",
     "start_time": "2024-06-10T02:50:41.499082Z"
    }
   },
   "source": [
    "for inputs, targets in binary_1gram_train_ds:\n",
    "    print(\"inputs.shape:\", inputs.shape)\n",
    "    print(\"inputs.dtype:\", inputs.dtype)\n",
    "    print(\"targets.shape:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets[0])\n",
    "    break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32, 20000)\n",
      "inputs.dtype: <dtype: 'float32'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
      "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Our model-building utility**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:50:43.220196Z",
     "start_time": "2024-06-10T02:50:43.215849Z"
    }
   },
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def get_model(max_tokens=20000, hidden_dim=16):\n",
    "    inputs = keras.Input(shape=(max_tokens,))\n",
    "    x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training and testing the binary unigram model**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:52:01.614413Z",
     "start_time": "2024-06-10T02:50:44.245656Z"
    }
   },
   "source": [
    "model = get_model()\n",
    "model.summary()\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "model.fit(binary_1gram_train_ds.cache(),\n",
    "          validation_data=binary_1gram_val_ds.cache(),\n",
    "          epochs=10,\n",
    "          callbacks=callbacks)\n",
    "model = keras.models.load_model(\"binary_1gram.keras\")\n",
    "print(f\"Test acc: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                320016    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,033\n",
      "Trainable params: 320,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 11:50:44.642039: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - ETA: 0s - loss: 0.3934 - accuracy: 0.8324"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 11:50:54.013231: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 10s 13ms/step - loss: 0.3934 - accuracy: 0.8324 - val_loss: 0.2796 - val_accuracy: 0.8924\n",
      "Epoch 2/10\n",
      "704/704 [==============================] - 7s 11ms/step - loss: 0.2164 - accuracy: 0.9245 - val_loss: 0.3503 - val_accuracy: 0.8604\n",
      "Epoch 3/10\n",
      "704/704 [==============================] - 7s 10ms/step - loss: 0.1584 - accuracy: 0.9502 - val_loss: 0.3915 - val_accuracy: 0.8580\n",
      "Epoch 4/10\n",
      "704/704 [==============================] - 7s 9ms/step - loss: 0.1279 - accuracy: 0.9629 - val_loss: 0.4342 - val_accuracy: 0.8592\n",
      "Epoch 5/10\n",
      "704/704 [==============================] - 7s 9ms/step - loss: 0.1078 - accuracy: 0.9694 - val_loss: 0.4879 - val_accuracy: 0.8564\n",
      "Epoch 6/10\n",
      "704/704 [==============================] - 7s 9ms/step - loss: 0.0942 - accuracy: 0.9739 - val_loss: 0.5476 - val_accuracy: 0.8516\n",
      "Epoch 7/10\n",
      "704/704 [==============================] - 7s 10ms/step - loss: 0.0835 - accuracy: 0.9768 - val_loss: 0.6555 - val_accuracy: 0.8384\n",
      "Epoch 8/10\n",
      "704/704 [==============================] - 7s 9ms/step - loss: 0.0742 - accuracy: 0.9787 - val_loss: 0.7236 - val_accuracy: 0.8356\n",
      "Epoch 9/10\n",
      "704/704 [==============================] - 7s 10ms/step - loss: 0.0679 - accuracy: 0.9807 - val_loss: 0.8329 - val_accuracy: 0.8312\n",
      "Epoch 10/10\n",
      "704/704 [==============================] - 7s 10ms/step - loss: 0.0613 - accuracy: 0.9819 - val_loss: 0.8931 - val_accuracy: 0.8344\n",
      "  8/782 [..............................] - ETA: 6s - loss: 0.2731 - accuracy: 0.8984  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 11:51:55.918056: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2894 - accuracy: 0.8886\n",
      "Test acc: 0.889\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Bigrams with binary encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Configuring the `TextVectorization` layer to return bigrams**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:52:01.620782Z",
     "start_time": "2024-06-10T02:52:01.616712Z"
    }
   },
   "source": [
    "text_vectorization = TextVectorization(\n",
    "    ngrams=2,\n",
    "    max_tokens=20000,\n",
    "    output_mode=\"multi_hot\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training and testing the binary bigram model**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:53:26.654703Z",
     "start_time": "2024-06-10T02:52:01.621522Z"
    }
   },
   "source": [
    "text_vectorization.adapt(text_only_train_ds)\n",
    "binary_2gram_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "binary_2gram_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "binary_2gram_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "\n",
    "model = get_model()\n",
    "model.summary()\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "model.fit(binary_2gram_train_ds.cache(),\n",
    "          validation_data=binary_2gram_val_ds.cache(),\n",
    "          epochs=10,\n",
    "          callbacks=callbacks)\n",
    "model = keras.models.load_model(\"binary_2gram.keras\")\n",
    "print(f\"Test acc: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 11:52:01.646509: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                320016    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,033\n",
      "Trainable params: 320,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 11:52:11.975335: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - ETA: 0s - loss: 0.3749 - accuracy: 0.8444"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 11:52:18.904133: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 8s 10ms/step - loss: 0.3749 - accuracy: 0.8444 - val_loss: 0.3023 - val_accuracy: 0.8812\n",
      "Epoch 2/10\n",
      "704/704 [==============================] - 7s 9ms/step - loss: 0.1776 - accuracy: 0.9438 - val_loss: 0.3640 - val_accuracy: 0.8624\n",
      "Epoch 3/10\n",
      "704/704 [==============================] - 7s 9ms/step - loss: 0.1157 - accuracy: 0.9700 - val_loss: 0.4151 - val_accuracy: 0.8588\n",
      "Epoch 4/10\n",
      "704/704 [==============================] - 7s 10ms/step - loss: 0.0862 - accuracy: 0.9783 - val_loss: 0.5167 - val_accuracy: 0.8428\n",
      "Epoch 5/10\n",
      "704/704 [==============================] - 7s 10ms/step - loss: 0.0682 - accuracy: 0.9824 - val_loss: 0.5707 - val_accuracy: 0.8512\n",
      "Epoch 6/10\n",
      "704/704 [==============================] - 7s 9ms/step - loss: 0.0552 - accuracy: 0.9857 - val_loss: 0.7403 - val_accuracy: 0.8300\n",
      "Epoch 7/10\n",
      "704/704 [==============================] - 7s 10ms/step - loss: 0.0469 - accuracy: 0.9872 - val_loss: 0.8342 - val_accuracy: 0.8352\n",
      "Epoch 8/10\n",
      "704/704 [==============================] - 7s 10ms/step - loss: 0.0402 - accuracy: 0.9882 - val_loss: 0.9777 - val_accuracy: 0.8296\n",
      "Epoch 9/10\n",
      "704/704 [==============================] - 7s 9ms/step - loss: 0.0356 - accuracy: 0.9892 - val_loss: 1.0833 - val_accuracy: 0.8320\n",
      "Epoch 10/10\n",
      "704/704 [==============================] - 7s 9ms/step - loss: 0.0322 - accuracy: 0.9898 - val_loss: 1.2372 - val_accuracy: 0.8252\n",
      "  8/782 [..............................] - ETA: 5s - loss: 0.2242 - accuracy: 0.9219  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 11:53:20.544827: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 6s 8ms/step - loss: 0.2779 - accuracy: 0.8974\n",
      "Test acc: 0.897\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Bigrams with TF-IDF encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Configuring the `TextVectorization` layer to return token counts**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:53:26.663169Z",
     "start_time": "2024-06-10T02:53:26.659194Z"
    }
   },
   "source": [
    "text_vectorization = TextVectorization(\n",
    "    ngrams=2,\n",
    "    max_tokens=20000,\n",
    "    output_mode=\"count\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Configuring `TextVectorization` to return TF-IDF-weighted outputs**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:53:26.668557Z",
     "start_time": "2024-06-10T02:53:26.663902Z"
    }
   },
   "source": [
    "text_vectorization = TextVectorization(\n",
    "    ngrams=2,\n",
    "    max_tokens=20000,\n",
    "    output_mode=\"tf_idf\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training and testing the TF-IDF bigram model**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:55:14.608852Z",
     "start_time": "2024-06-10T02:53:26.669295Z"
    }
   },
   "source": [
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "tfidf_2gram_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "tfidf_2gram_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "tfidf_2gram_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "\n",
    "model = get_model()\n",
    "model.summary()\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"tfidf_2gram.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "model.fit(tfidf_2gram_train_ds.cache(),\n",
    "          validation_data=tfidf_2gram_val_ds.cache(),\n",
    "          epochs=10,\n",
    "          callbacks=callbacks)\n",
    "model = keras.models.load_model(\"tfidf_2gram.keras\")\n",
    "print(f\"Test acc: {model.evaluate(tfidf_2gram_test_ds)[1]:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 11:53:26.728047: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                320016    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,033\n",
      "Trainable params: 320,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 11:53:59.208631: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - ETA: 0s - loss: 0.5222 - accuracy: 0.7847"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 11:54:07.703156: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 9s 13ms/step - loss: 0.5222 - accuracy: 0.7847 - val_loss: 0.1550 - val_accuracy: 0.9516\n",
      "Epoch 2/10\n",
      "704/704 [==============================] - 7s 10ms/step - loss: 0.2930 - accuracy: 0.8968 - val_loss: 0.1705 - val_accuracy: 0.9168\n",
      "Epoch 3/10\n",
      "704/704 [==============================] - 7s 10ms/step - loss: 0.1950 - accuracy: 0.9323 - val_loss: 0.2359 - val_accuracy: 0.8924\n",
      "Epoch 4/10\n",
      "704/704 [==============================] - 7s 10ms/step - loss: 0.1465 - accuracy: 0.9494 - val_loss: 0.2488 - val_accuracy: 0.8920\n",
      "Epoch 5/10\n",
      "704/704 [==============================] - 7s 10ms/step - loss: 0.1168 - accuracy: 0.9605 - val_loss: 0.2649 - val_accuracy: 0.8976\n",
      "Epoch 6/10\n",
      "704/704 [==============================] - 7s 9ms/step - loss: 0.0989 - accuracy: 0.9695 - val_loss: 0.2889 - val_accuracy: 0.8872\n",
      "Epoch 7/10\n",
      "704/704 [==============================] - 7s 9ms/step - loss: 0.0856 - accuracy: 0.9748 - val_loss: 0.4382 - val_accuracy: 0.8436\n",
      "Epoch 8/10\n",
      "704/704 [==============================] - 7s 9ms/step - loss: 0.0762 - accuracy: 0.9780 - val_loss: 0.3963 - val_accuracy: 0.8628\n",
      "Epoch 9/10\n",
      "704/704 [==============================] - 7s 9ms/step - loss: 0.0703 - accuracy: 0.9807 - val_loss: 0.3973 - val_accuracy: 0.8684\n",
      "Epoch 10/10\n",
      "704/704 [==============================] - 7s 9ms/step - loss: 0.0639 - accuracy: 0.9828 - val_loss: 0.4305 - val_accuracy: 0.8656\n",
      "  8/782 [..............................] - ETA: 5s - loss: 0.4363 - accuracy: 0.8164  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 11:55:08.858900: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3915 - accuracy: 0.8443\n",
      "Test acc: 0.844\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:55:14.638860Z",
     "start_time": "2024-06-10T02:55:14.609846Z"
    }
   },
   "source": [
    "inputs = keras.Input(shape=(1,), dtype=\"string\")\n",
    "processed_inputs = text_vectorization(inputs)\n",
    "outputs = model(processed_inputs)\n",
    "inference_model = keras.Model(inputs, outputs)"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "ExecuteTime": {
     "end_time": "2024-06-10T02:55:15.291478Z",
     "start_time": "2024-06-10T02:55:14.639777Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "raw_text_data = tf.convert_to_tensor([\n",
    "    [\"That was an excellent movie, I loved it.\"],\n",
    "])\n",
    "predictions = inference_model(raw_text_data)\n",
    "print(f\"{float(predictions[0] * 100):.2f} percent positive\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.34 percent positive\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter11_part01_introduction.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
